{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea57468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!/usr/bin/env python\n",
    "# # coding: utf-8\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# from flask import Flask, render_template, request\n",
    "# from flask import Flask, request, jsonify\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.svm import LinearSVC\n",
    "# import re\n",
    "# import string\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# import pickle\n",
    "\n",
    "# # Define the Flask application\n",
    "# app = Flask(__name__)\n",
    "\n",
    "# # Load the pre-trained SVM model\n",
    "# model = pickle.load(open('./best_SVC_Model.pickle','rb')) #read mode\n",
    "\n",
    "# @app.route(\"/\")\n",
    "# def home():\n",
    "#     return render_template('index.html')\n",
    "\n",
    "# @app.route(\"/predict\", methods=['POST'])\n",
    "# def predict():\n",
    "    \n",
    "#     if request.is_json:\n",
    "#         # Get the input data from the request\n",
    "#         data = request.form['input']\n",
    "#         print(\"data is\", data)\n",
    "        \n",
    "#         # Extract the user input from the request\n",
    "#         user_input = data['input']\n",
    "\n",
    "#         # Preprocess the user input\n",
    "#         preprocessed_input = preprocess(user_input)\n",
    "\n",
    "#         # Initialize the TF-IDF vectorizer\n",
    "#         vectorizer = TfidfVectorizer()\n",
    "\n",
    "#         # Vectorize the preprocessed input using TF-IDF\n",
    "#         vectorized_input = vectorizer.transform([preprocessed_input])\n",
    "\n",
    "#         # Use the pre-trained model to make predictions\n",
    "#         prediction = model.predict(vectorized_input)\n",
    "\n",
    "#         # Map the prediction to a sentiment label\n",
    "#         sentiment = 'positive' if prediction[0] == 1 else 'negative'\n",
    "\n",
    "#         # Return the sentiment label as a JSON response\n",
    "#         response = jsonify({'sentiment': sentiment})\n",
    "#         response.headers.add('Content-Type', 'application/json')\n",
    "#         return response\n",
    "\n",
    "#     else:\n",
    "#         print(request)\n",
    "#         return 'Invalid request content type', 400\n",
    "\n",
    "\n",
    "# def preprocess(text):\n",
    "#     # Remove punctuation and lowercase the text\n",
    "#     text = text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "\n",
    "#     # Tokenize the text into words\n",
    "#     words = nltk.word_tokenize(text)\n",
    "\n",
    "#     # Remove stop words\n",
    "#     words = [word for word in words if word not in stopwords.words('english')]\n",
    "\n",
    "#     # Lemmatize the words\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "#     # Join the words back into a string\n",
    "#     text = ' '.join(words)\n",
    "\n",
    "#     return text\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     app.run(debug=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc79f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eugen\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3468: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from flask import Flask, render_template, request\n",
    "from flask import Flask, request, jsonify\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pickle\n",
    "import requests\n",
    "\n",
    "# Define the Flask application\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the pre-trained SVM model\n",
    "model = pickle.load(open('./best_SVC_Model.pickle','rb')) #read mode\n",
    "\n",
    "\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    \n",
    "    print(\"TEST: \",  request.form.values())\n",
    "    if request.is_json:\n",
    "        # Get the input data from the request\n",
    "        data = request.form['input']\n",
    "        print(\"data is\", data)\n",
    "        \n",
    "        # Extract the user input from the request\n",
    "        user_input = data['input']\n",
    "\n",
    "        # Preprocess the user input\n",
    "        preprocessed_input = preprocess(user_input)\n",
    "\n",
    "        # Initialize the TF-IDF vectorizer\n",
    "        vectorizer = TfidfVectorizer()\n",
    "\n",
    "        # Vectorize the preprocessed input using TF-IDF\n",
    "        vectorized_input = vectorizer.transform([preprocessed_input])\n",
    "\n",
    "        # Use the pre-trained model to make predictions\n",
    "        prediction = model.predict(vectorized_input)\n",
    "\n",
    "        # Map the prediction to a sentiment label\n",
    "        sentiment = 'positive' if prediction[0] == 1 else 'negative'\n",
    "\n",
    "        # Return the sentiment label as a JSON response\n",
    "        response = jsonify({'sentiment': sentiment})\n",
    "        response.headers.add('Content-Type', 'application/json')\n",
    "        return response\n",
    "\n",
    "    else:\n",
    "        print(request)\n",
    "        return 'Invalid request content type', 400\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    # Remove punctuation and lowercase the text\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "\n",
    "    # Lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Join the words back into a string\n",
    "    text = ' '.join(words)\n",
    "\n",
    "    return text\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7242ad62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
